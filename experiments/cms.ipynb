{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a027068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_rel\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Type, Dict, Optional\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import Optimizer\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c76ae3",
   "metadata": {},
   "source": [
    "## Permuted MNIST Task Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc784ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PermutedMNIST:\n",
    "    def __init__(self, perm):\n",
    "        self.perm = perm\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x.view(-1)[perm])\n",
    "        ])\n",
    "\n",
    "    def train_loader(self, batch_size=128):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            datasets.MNIST(\"./data\", train=True, download=True, transform=self.transform),\n",
    "            batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    def test_loader(self, batch_size=1000):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            datasets.MNIST(\"./data\", train=False, transform=self.transform),\n",
    "            batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0f56f4",
   "metadata": {},
   "source": [
    "## CMS Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04a1cefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CMSGroup:\n",
    "    params: List[torch.nn.Parameter]\n",
    "    lr: float\n",
    "    chunk: int\n",
    "\n",
    "class CMSOptimizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        groups: List[CMSGroup],\n",
    "        base_optim_cls: Type[Optimizer],\n",
    "        base_optim_kwargs: Optional[Dict] = None,\n",
    "    ):\n",
    "        self.step_idx = 0\n",
    "        self.groups = groups\n",
    "        base_optim_kwargs = base_optim_kwargs or {}\n",
    "        self.opts = [base_optim_cls(g.params, lr=g.lr, **base_optim_kwargs) for g in groups]\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def step(self):\n",
    "        self.step_idx += 1\n",
    "        for opt, g in zip(self.opts, self.groups):\n",
    "            if (self.step_idx % g.chunk) == 0:\n",
    "                opt.step()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for opt, g in zip(self.opts, self.groups):\n",
    "            if ((self.step_idx)% g.chunk) == 0:\n",
    "                opt.zero_grad()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba84523",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c0d023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, \n",
    "        input_dim=784,\n",
    "        hidden_dims=[256, 128, 64],\n",
    "        output_dim=10,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        assert len(hidden_dims) == 3\n",
    "        self.slow = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dims[0]),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.mid = nn.Sequential(\n",
    "            nn.Linear(hidden_dims[0], hidden_dims[1]),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fast = nn.Sequential(\n",
    "            nn.Linear(hidden_dims[1], hidden_dims[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims[2], output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.slow(x)\n",
    "        h = self.mid(h)\n",
    "        y = self.fast(h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a15a32d",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62ff0370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forgetting_matrix(acc_matrix: np.ndarray) -> np.ndarray:\n",
    "    T = acc_matrix.shape[0]\n",
    "    F = np.zeros_like(acc_matrix)\n",
    "\n",
    "    for i in range(T):          # task\n",
    "        best_so_far = acc_matrix[i, i]  # first time task i is learned\n",
    "        for j in range(i, T):   # after task j\n",
    "            best_so_far = max(best_so_far, acc_matrix[i, j])\n",
    "            F[i, j] = best_so_far - acc_matrix[i, j]\n",
    "\n",
    "    return F\n",
    "\n",
    "def compute_avg_forgetting(acc_matrix: np.ndarray) -> float:\n",
    "    T = acc_matrix.shape[0]\n",
    "    forgets = []\n",
    "    for i in range(T - 1):\n",
    "        best = acc_matrix[i, i:].max()\n",
    "        final = acc_matrix[i, T - 1]\n",
    "        forgets.append(best - final)\n",
    "    return float(np.mean(forgets))\n",
    "\n",
    "def compute_avg_accuracy(acc_matrix: np.ndarray) -> float:\n",
    "    T = acc_matrix.shape[0]\n",
    "    return float(acc_matrix[:, T - 1].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91bb999",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2182f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device) -> float:\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x).argmax(1)\n",
    "            correct += (pred == y).sum().item()\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "371f2250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_permuted_mnist_cms_experiment(\n",
    "    T=9,\n",
    "    epochs_per_task=8,\n",
    "    batch_size=128,\n",
    "    hidden_dims=(256, 128, 64),\n",
    "    base_lr=5e-4,\n",
    "    periods=(4, 2, 1),\n",
    "    device=None,\n",
    "    seed=None,\n",
    "    verbose=False,\n",
    "):\n",
    "    # --- device ---\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # --- reproducibility (optional) ---\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # --- datasets ---\n",
    "    g = torch.Generator().manual_seed(seed) if seed is not None else None\n",
    "    perms = [torch.randperm(784, generator=g) for _ in range(T)]\n",
    "    tasks = [PermutedMNIST(p) for p in perms]\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # --- baseline ---\n",
    "    baseline_mlp = MLP(784, list(hidden_dims), 10).to(device)\n",
    "    baseline_optimizer = CMSOptimizer(\n",
    "        groups=[CMSGroup(params=list(baseline_mlp.parameters()), lr=base_lr, chunk=1)],\n",
    "        base_optim_cls=optim.Adam,\n",
    "    )\n",
    "\n",
    "    # --- CMS ---\n",
    "    frequencies = [base_lr / p for p in periods]\n",
    "    seq_cms = MLP(784, list(hidden_dims), 10).to(device)\n",
    "    seq_cms_optimizer = CMSOptimizer(\n",
    "        groups=[\n",
    "            CMSGroup(params=list(seq_cms.slow.parameters()), lr=frequencies[0], chunk=periods[0]),\n",
    "            CMSGroup(params=list(seq_cms.mid.parameters()),  lr=frequencies[1], chunk=periods[1]),\n",
    "            CMSGroup(params=list(seq_cms.fast.parameters()), lr=frequencies[2], chunk=periods[2]),\n",
    "        ],\n",
    "        base_optim_cls=optim.Adam,\n",
    "    )\n",
    "\n",
    "    # --- results ---\n",
    "    acc_matrix_baseline = np.zeros((T, T), dtype=np.float32)\n",
    "    acc_matrix_cms      = np.zeros((T, T), dtype=np.float32)\n",
    "\n",
    "    # --- train sequentially ---\n",
    "    for current_t in range(T):\n",
    "        train_loader = tasks[current_t].train_loader(batch_size=batch_size)\n",
    "\n",
    "        baseline_mlp.train()\n",
    "        seq_cms.train()\n",
    "\n",
    "        for _ in range(epochs_per_task):\n",
    "            for x, y in train_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "\n",
    "                # baseline\n",
    "                baseline_optimizer.zero_grad()\n",
    "                loss = loss_fn(baseline_mlp(x), y)\n",
    "                loss.backward()\n",
    "                baseline_optimizer.step()\n",
    "\n",
    "                # cms\n",
    "                seq_cms_optimizer.zero_grad()\n",
    "                loss = loss_fn(seq_cms(x), y)\n",
    "                loss.backward()\n",
    "                seq_cms_optimizer.step()\n",
    "\n",
    "        # --- evaluation + optional printing ---\n",
    "        if verbose:\n",
    "            print(\"\\nEvaluation after training task\", current_t + 1)\n",
    "            print(\"-\" * 55)\n",
    "            print(f\"{'Eval Task':<10} | {'Baseline MLP':<15} | {'Seq CMS':<15}\")\n",
    "            print(\"-\" * 55)\n",
    "\n",
    "        for i in range(T):\n",
    "            acc_matrix_baseline[i, current_t] = evaluate(\n",
    "                baseline_mlp, tasks[i].test_loader(), device\n",
    "            )\n",
    "            acc_matrix_cms[i, current_t] = evaluate(\n",
    "                seq_cms, tasks[i].test_loader(), device\n",
    "            )\n",
    "\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"{i+1:<10} | \"\n",
    "                    f\"{acc_matrix_baseline[i, current_t]*100:>6.2f}%{'':<7} | \"\n",
    "                    f\"{acc_matrix_cms[i, current_t]*100:>6.2f}%\"\n",
    "                )\n",
    "\n",
    "        if verbose:\n",
    "            print(\"-\" * 55)\n",
    "\n",
    "    return acc_matrix_baseline, acc_matrix_cms\n",
    "\n",
    "def run_n_times(n_runs=5, seed=None, verbose=False, **kwargs):\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"ðŸš€ Running Permuted-MNIST Continual Learning Experiment\")\n",
    "        print(f\"Total runs: {n_runs}\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "    base_forgets, cms_forgets = [], []\n",
    "    base_accs, cms_accs = [], []\n",
    "\n",
    "    for k in range(n_runs):\n",
    "\n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"-\" * 70)\n",
    "            print(f\"â–¶ Run {k + 1}/{n_runs}\")\n",
    "            print(\"-\" * 70)\n",
    "\n",
    "        run_seed = seed + k if seed is not None else None\n",
    "        A_base, A_cms = run_permuted_mnist_cms_experiment(\n",
    "            verbose=verbose,\n",
    "            seed=run_seed,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        bF = compute_avg_forgetting(A_base)\n",
    "        cF = compute_avg_forgetting(A_cms)\n",
    "        bA = compute_avg_accuracy(A_base)\n",
    "        cA = compute_avg_accuracy(A_cms)\n",
    "\n",
    "        base_forgets.append(bF)\n",
    "        cms_forgets.append(cF)\n",
    "        base_accs.append(bA)\n",
    "        cms_accs.append(cA)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"\\nðŸ“Š Run summary\")\n",
    "            print(f\"  Baseline | Avg Acc: {bA*100:6.2f}% | Forgetting: {bF*100:6.2f}%\")\n",
    "            print(f\"  CMS      | Avg Acc: {cA*100:6.2f}% | Forgetting: {cF*100:6.2f}%\")\n",
    "\n",
    "    report = {\n",
    "        \"baseline_avg_acc_mean\":    float(np.mean(base_accs)),\n",
    "        \"baseline_avg_acc_std\":     float(np.std(base_accs, ddof=1)) if n_runs > 1 else 0.0,\n",
    "        \"cms_avg_acc_mean\":         float(np.mean(cms_accs)),\n",
    "        \"cms_avg_acc_std\":          float(np.std(cms_accs, ddof=1)) if n_runs > 1 else 0.0,\n",
    "        \"baseline_forgetting_mean\": float(np.mean(base_forgets)),\n",
    "        \"baseline_forgetting_std\":  float(np.std(base_forgets, ddof=1)) if n_runs > 1 else 0.0,\n",
    "        \"cms_forgetting_mean\":      float(np.mean(cms_forgets)),\n",
    "        \"cms_forgetting_std\":       float(np.std(cms_forgets, ddof=1)) if n_runs > 1 else 0.0,\n",
    "        \"baseline_forgetting_all\":  base_forgets,\n",
    "        \"cms_forgetting_all\":       cms_forgets,\n",
    "        \"baseline_acc_all\":         base_accs,\n",
    "        \"cms_acc_all\":              cms_accs,\n",
    "    }\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"âœ… Final Continual Learning Report (mean Â± std)\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Average Accuracy  - Baseline: {report['baseline_avg_acc_mean']*100:6.2f}% Â± {report['baseline_avg_acc_std']*100:5.2f}%\")\n",
    "    print(f\"Average Accuracy  - CMS     : {report['cms_avg_acc_mean']*100:6.2f}% Â± {report['cms_avg_acc_std']*100:5.2f}%\")\n",
    "    print(f\"Avg Forgetting    - Baseline: {report['baseline_forgetting_mean']*100:6.2f}% Â± {report['baseline_forgetting_std']*100:5.2f}%\")\n",
    "    print(f\"Avg Forgetting    - CMS     : {report['cms_forgetting_mean']*100:6.2f}% Â± {report['cms_forgetting_std']*100:5.2f}%\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e41fad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs=5\n",
    "seed=0\n",
    "verbose=True\n",
    "T=9\n",
    "epochs_per_task=8\n",
    "batch_size=128\n",
    "base_lr=5e-4\n",
    "periods=(4,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a945668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸš€ Running Permuted-MNIST Continual Learning Experiment\n",
      "Total runs: 5\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "â–¶ Run 1/5\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomas-osarte/Desktop/TUDelft/Master/Thesis/catastrophic_forgetting/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:182: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:119.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation after training task 1\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  97.74%        |  96.92%\n",
      "2          |   9.23%        |  11.07%\n",
      "3          |  13.22%        |  11.21%\n",
      "4          |  10.01%        |  10.52%\n",
      "5          |  11.46%        |  10.56%\n",
      "6          |   7.46%        |  11.42%\n",
      "7          |   8.29%        |   9.48%\n",
      "8          |   9.02%        |  12.33%\n",
      "9          |   7.12%        |  10.07%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 2\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  87.95%        |  90.21%\n",
      "2          |  97.78%        |  97.25%\n",
      "3          |  10.16%        |  10.40%\n",
      "4          |   8.73%        |  12.53%\n",
      "5          |  11.35%        |   7.48%\n",
      "6          |  10.98%        |  11.42%\n",
      "7          |   5.27%        |   6.69%\n",
      "8          |   8.68%        |   9.39%\n",
      "9          |   9.78%        |  10.63%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 3\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  78.41%        |  73.52%\n",
      "2          |  92.72%        |  89.84%\n",
      "3          |  97.83%        |  97.33%\n",
      "4          |  12.03%        |  10.20%\n",
      "5          |   8.89%        |   8.40%\n",
      "6          |  14.86%        |  13.68%\n",
      "7          |   5.87%        |   8.68%\n",
      "8          |   7.49%        |   9.78%\n",
      "9          |   7.62%        |  11.74%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 4\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  39.45%        |  54.09%\n",
      "2          |  81.36%        |  80.01%\n",
      "3          |  92.89%        |  94.15%\n",
      "4          |  97.66%        |  97.39%\n",
      "5          |  10.86%        |   9.49%\n",
      "6          |  12.42%        |  11.64%\n",
      "7          |   8.05%        |   6.33%\n",
      "8          |   7.06%        |   8.88%\n",
      "9          |  10.05%        |   9.58%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 5\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  44.55%        |  43.91%\n",
      "2          |  70.17%        |  64.41%\n",
      "3          |  86.53%        |  89.81%\n",
      "4          |  92.03%        |  93.06%\n",
      "5          |  97.31%        |  97.42%\n",
      "6          |  10.15%        |   9.53%\n",
      "7          |   9.15%        |   5.13%\n",
      "8          |   8.68%        |  10.79%\n",
      "9          |   7.80%        |   8.57%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 6\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  36.68%        |  36.67%\n",
      "2          |  64.02%        |  59.36%\n",
      "3          |  72.18%        |  81.30%\n",
      "4          |  78.50%        |  83.91%\n",
      "5          |  92.44%        |  93.95%\n",
      "6          |  97.45%        |  97.29%\n",
      "7          |   9.54%        |   5.91%\n",
      "8          |   9.14%        |   9.15%\n",
      "9          |  10.04%        |   7.72%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 7\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  32.01%        |  23.11%\n",
      "2          |  52.15%        |  44.92%\n",
      "3          |  36.46%        |  60.78%\n",
      "4          |  60.18%        |  69.40%\n",
      "5          |  70.25%        |  83.14%\n",
      "6          |  90.72%        |  95.08%\n",
      "7          |  97.37%        |  97.50%\n",
      "8          |   8.57%        |   9.22%\n",
      "9          |  10.27%        |   9.49%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 8\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  28.16%        |  20.41%\n",
      "2          |  46.45%        |  33.87%\n",
      "3          |  29.72%        |  49.85%\n",
      "4          |  48.11%        |  41.83%\n",
      "5          |  46.93%        |  62.51%\n",
      "6          |  73.29%        |  85.89%\n",
      "7          |  87.52%        |  93.30%\n",
      "8          |  97.33%        |  97.21%\n",
      "9          |   9.31%        |   8.78%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 9\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  16.70%        |  20.34%\n",
      "2          |  25.91%        |  29.23%\n",
      "3          |  24.90%        |  36.25%\n",
      "4          |  31.25%        |  28.07%\n",
      "5          |  34.16%        |  47.29%\n",
      "6          |  36.96%        |  65.53%\n",
      "7          |  60.51%        |  78.15%\n",
      "8          |  91.89%        |  93.42%\n",
      "9          |  97.42%        |  97.17%\n",
      "-------------------------------------------------------\n",
      "\n",
      "ðŸ“Š Run summary\n",
      "  Baseline | Avg Acc:  46.63% | Forgetting:  57.27%\n",
      "  CMS      | Avg Acc:  55.05% | Forgetting:  47.50%\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "â–¶ Run 2/5\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 1\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  97.63%        |  96.70%\n",
      "2          |  13.17%        |  11.89%\n",
      "3          |  10.74%        |  10.17%\n",
      "4          |   6.15%        |   8.97%\n",
      "5          |  10.27%        |   7.70%\n",
      "6          |   8.94%        |   6.14%\n",
      "7          |   6.50%        |   8.73%\n",
      "8          |  10.36%        |   9.19%\n",
      "9          |   9.52%        |   6.58%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 2\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  91.63%        |  88.75%\n",
      "2          |  97.40%        |  97.01%\n",
      "3          |   9.58%        |  10.41%\n",
      "4          |  11.66%        |  14.03%\n",
      "5          |  10.95%        |   8.82%\n",
      "6          |  11.38%        |   9.94%\n",
      "7          |   6.46%        |  10.69%\n",
      "8          |   9.93%        |   6.26%\n",
      "9          |  12.23%        |   8.96%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 3\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  73.80%        |  78.94%\n",
      "2          |  92.68%        |  92.88%\n",
      "3          |  97.73%        |  97.27%\n",
      "4          |  10.45%        |   9.85%\n",
      "5          |  12.33%        |  10.77%\n",
      "6          |   9.20%        |   9.93%\n",
      "7          |   7.78%        |  11.61%\n",
      "8          |   8.96%        |   8.88%\n",
      "9          |   8.74%        |   8.18%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 4\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  52.89%        |  75.92%\n",
      "2          |  81.02%        |  88.69%\n",
      "3          |  92.83%        |  92.08%\n",
      "4          |  97.60%        |  97.13%\n",
      "5          |   9.26%        |   8.26%\n",
      "6          |  10.06%        |   7.16%\n",
      "7          |   9.34%        |   9.59%\n",
      "8          |  10.64%        |   6.77%\n",
      "9          |   9.13%        |   6.73%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 5\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  40.38%        |  62.25%\n",
      "2          |  60.57%        |  78.04%\n",
      "3          |  79.02%        |  84.99%\n",
      "4          |  94.82%        |  94.95%\n",
      "5          |  97.38%        |  97.25%\n",
      "6          |  11.38%        |   7.15%\n",
      "7          |   8.92%        |   7.98%\n",
      "8          |  10.38%        |  16.10%\n",
      "9          |  11.23%        |   9.69%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 6\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  27.62%        |  50.29%\n",
      "2          |  33.37%        |  66.65%\n",
      "3          |  66.26%        |  64.71%\n",
      "4          |  82.69%        |  88.81%\n",
      "5          |  91.52%        |  91.51%\n",
      "6          |  97.37%        |  97.30%\n",
      "7          |   7.79%        |   8.52%\n",
      "8          |  10.97%        |  11.08%\n",
      "9          |  10.94%        |   7.10%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 7\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  32.01%        |  44.01%\n",
      "2          |  39.55%        |  52.75%\n",
      "3          |  48.32%        |  47.49%\n",
      "4          |  68.38%        |  76.22%\n",
      "5          |  82.80%        |  83.27%\n",
      "6          |  89.74%        |  90.92%\n",
      "7          |  97.77%        |  97.22%\n",
      "8          |  10.29%        |  13.43%\n",
      "9          |  10.89%        |   9.25%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 8\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  25.33%        |  25.18%\n",
      "2          |  27.87%        |  36.16%\n",
      "3          |  37.23%        |  36.64%\n",
      "4          |  41.21%        |  56.75%\n",
      "5          |  67.20%        |  70.70%\n",
      "6          |  69.47%        |  74.02%\n",
      "7          |  92.20%        |  91.73%\n",
      "8          |  97.62%        |  97.17%\n",
      "9          |  11.17%        |  11.51%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 9\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  20.42%        |  18.11%\n",
      "2          |  22.87%        |  28.76%\n",
      "3          |  33.47%        |  29.38%\n",
      "4          |  37.41%        |  34.13%\n",
      "5          |  56.02%        |  53.25%\n",
      "6          |  57.47%        |  53.39%\n",
      "7          |  72.42%        |  83.84%\n",
      "8          |  93.84%        |  92.95%\n",
      "9          |  97.37%        |  97.29%\n",
      "-------------------------------------------------------\n",
      "\n",
      "ðŸ“Š Run summary\n",
      "  Baseline | Avg Acc:  54.59% | Forgetting:  48.32%\n",
      "  CMS      | Avg Acc:  54.57% | Forgetting:  47.90%\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "â–¶ Run 3/5\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 1\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  97.55%        |  96.77%\n",
      "2          |   8.71%        |  10.71%\n",
      "3          |  14.28%        |  12.89%\n",
      "4          |  13.39%        |   9.43%\n",
      "5          |  11.68%        |  12.37%\n",
      "6          |   8.02%        |  12.16%\n",
      "7          |  11.48%        |   7.13%\n",
      "8          |  11.56%        |  12.12%\n",
      "9          |   9.48%        |  11.49%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 2\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  88.44%        |  91.84%\n",
      "2          |  97.54%        |  97.20%\n",
      "3          |  12.12%        |  15.05%\n",
      "4          |   7.33%        |   7.84%\n",
      "5          |   9.90%        |  12.79%\n",
      "6          |   9.75%        |   9.54%\n",
      "7          |   5.15%        |   6.19%\n",
      "8          |  12.11%        |  10.78%\n",
      "9          |   8.85%        |   9.57%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 3\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  54.07%        |  73.43%\n",
      "2          |  83.86%        |  87.45%\n",
      "3          |  97.70%        |  97.11%\n",
      "4          |  10.91%        |   7.96%\n",
      "5          |  13.11%        |  12.67%\n",
      "6          |   8.14%        |   8.77%\n",
      "7          |   7.08%        |  10.43%\n",
      "8          |  12.09%        |   8.90%\n",
      "9          |   6.47%        |   5.39%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 4\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  49.88%        |  72.12%\n",
      "2          |  75.96%        |  77.88%\n",
      "3          |  89.67%        |  91.92%\n",
      "4          |  97.76%        |  97.22%\n",
      "5          |  15.38%        |  11.78%\n",
      "6          |   8.35%        |   9.86%\n",
      "7          |  10.72%        |  11.43%\n",
      "8          |   6.65%        |   8.08%\n",
      "9          |   6.79%        |   4.64%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 5\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  34.21%        |  41.90%\n",
      "2          |  58.95%        |  63.02%\n",
      "3          |  82.68%        |  79.58%\n",
      "4          |  94.21%        |  87.40%\n",
      "5          |  97.66%        |  97.11%\n",
      "6          |   8.71%        |   9.56%\n",
      "7          |   8.60%        |  10.84%\n",
      "8          |  10.82%        |   9.91%\n",
      "9          |  10.53%        |   7.44%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 6\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  41.22%        |  44.63%\n",
      "2          |  38.82%        |  55.46%\n",
      "3          |  63.06%        |  63.64%\n",
      "4          |  81.15%        |  83.58%\n",
      "5          |  93.50%        |  93.91%\n",
      "6          |  97.40%        |  97.36%\n",
      "7          |   9.17%        |  10.04%\n",
      "8          |  10.18%        |   7.89%\n",
      "9          |   9.22%        |   9.17%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 7\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  28.70%        |  29.05%\n",
      "2          |  28.93%        |  41.48%\n",
      "3          |  49.06%        |  49.30%\n",
      "4          |  72.12%        |  71.53%\n",
      "5          |  84.48%        |  87.37%\n",
      "6          |  94.55%        |  93.64%\n",
      "7          |  97.70%        |  97.20%\n",
      "8          |  10.53%        |   9.92%\n",
      "9          |   7.10%        |   7.97%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 8\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  18.72%        |  26.14%\n",
      "2          |  20.73%        |  33.87%\n",
      "3          |  37.95%        |  29.55%\n",
      "4          |  55.47%        |  57.63%\n",
      "5          |  60.57%        |  71.94%\n",
      "6          |  77.65%        |  76.90%\n",
      "7          |  93.69%        |  85.13%\n",
      "8          |  97.40%        |  97.30%\n",
      "9          |   8.62%        |   7.55%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 9\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  23.29%        |  28.05%\n",
      "2          |  18.36%        |  26.31%\n",
      "3          |  24.85%        |  25.27%\n",
      "4          |  47.96%        |  50.56%\n",
      "5          |  40.73%        |  59.38%\n",
      "6          |  55.16%        |  76.08%\n",
      "7          |  76.81%        |  76.31%\n",
      "8          |  95.20%        |  94.63%\n",
      "9          |  97.50%        |  97.38%\n",
      "-------------------------------------------------------\n",
      "\n",
      "ðŸ“Š Run summary\n",
      "  Baseline | Avg Acc:  53.32% | Forgetting:  49.79%\n",
      "  CMS      | Avg Acc:  59.33% | Forgetting:  42.58%\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "â–¶ Run 4/5\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 1\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  97.66%        |  96.72%\n",
      "2          |   8.67%        |   9.45%\n",
      "3          |   8.62%        |   9.32%\n",
      "4          |   9.27%        |  11.63%\n",
      "5          |   9.29%        |   8.91%\n",
      "6          |   8.05%        |   6.63%\n",
      "7          |   8.96%        |   9.38%\n",
      "8          |  12.62%        |  11.90%\n",
      "9          |   9.04%        |   7.34%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 2\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  88.76%        |  86.66%\n",
      "2          |  97.80%        |  97.00%\n",
      "3          |  11.63%        |  11.02%\n",
      "4          |  13.57%        |  21.31%\n",
      "5          |  10.62%        |   9.27%\n",
      "6          |   8.03%        |   5.75%\n",
      "7          |   7.42%        |  11.01%\n",
      "8          |  12.09%        |  10.06%\n",
      "9          |   6.46%        |   7.91%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 3\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  77.35%        |  76.95%\n",
      "2          |  90.27%        |  91.54%\n",
      "3          |  97.61%        |  97.35%\n",
      "4          |  12.88%        |  15.80%\n",
      "5          |  10.25%        |   8.73%\n",
      "6          |   9.42%        |   4.72%\n",
      "7          |  10.56%        |  12.70%\n",
      "8          |   9.44%        |  10.53%\n",
      "9          |   8.01%        |  11.20%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Evaluation after training task 4\n",
      "-------------------------------------------------------\n",
      "Eval Task  | Baseline MLP    | Seq CMS        \n",
      "-------------------------------------------------------\n",
      "1          |  52.20%        |  68.47%\n",
      "2          |  77.09%        |  82.85%\n",
      "3          |  92.64%        |  87.89%\n",
      "4          |  97.87%        |  97.34%\n",
      "5          |  10.93%        |   9.71%\n",
      "6          |  12.58%        |   9.12%\n",
      "7          |  11.84%        |   7.87%\n",
      "8          |   9.16%        |  11.11%\n",
      "9          |   8.07%        |   7.83%\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "report = run_n_times(\n",
    "    n_runs=n_runs,\n",
    "    seed=seed,\n",
    "    verbose=verbose,\n",
    "    T=T,\n",
    "    epochs_per_task=epochs_per_task,\n",
    "    batch_size=batch_size,\n",
    "    base_lr=base_lr,\n",
    "    periods=periods,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c2edf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical significance test for forgetting\n",
    "baseline = report[\"baseline_forgetting_all\"]\n",
    "cms = report[\"cms_forgetting_all\"]\n",
    "t_stat, p_value = ttest_rel(baseline, cms)\n",
    "print(\"Statistical significance test for forgetting\")\n",
    "print(\"t-statistic :\", t_stat)\n",
    "print(\"p-value     :\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b139d6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical significance test for average accuracy\n",
    "baseline_avg = report[\"baseline_avg_acc_all\"]\n",
    "cms_avg = report[\"cms_avg_acc_all\"]\n",
    "t_stat_acc, p_value_acc = ttest_rel(baseline_avg, cms_avg)\n",
    "print(\"Statistical significance test for average accuracy\")\n",
    "print(\"t-statistic :\", t_stat_acc)\n",
    "print(\"p-value     :\", p_value_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d8186a",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dae8978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_evolution(acc_matrix_baseline_mlp, acc_matrix_seq_cms, max_cols=3):\n",
    "    num_tasks = acc_matrix_baseline_mlp.shape[0]\n",
    "    cols = min(max_cols, num_tasks)\n",
    "    rows = math.ceil(num_tasks / cols)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 3 * rows))\n",
    "    axes = np.array(axes).reshape(-1) \n",
    "\n",
    "    x = np.arange(1, num_tasks + 1)\n",
    "    for i, t in enumerate(range(num_tasks)):\n",
    "        ax = axes[i]\n",
    "        ax.plot(x, acc_matrix_baseline_mlp[t], marker=\"o\")\n",
    "        ax.plot(x, acc_matrix_seq_cms[t], marker=\"o\")\n",
    "        ax.set_title(f\"Task {t+1}\")\n",
    "        ax.set_xlabel(\"Eval Task\")\n",
    "        ax.set_ylabel(\"Accuracy\")\n",
    "        \n",
    "    fig.legend([\"Baseline MLP\", \"Sequential CMS\"], loc=\"lower center\", ncol=2)\n",
    "    fig.suptitle(f\"Accuracy evolution per task\", fontsize=14)\n",
    "    fig.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "def plot_task_forgetting(forget_matrix_baseline_mlp, forget_matrix_seq_cms, max_cols=3):\n",
    "    num_tasks = forget_matrix_baseline_mlp.shape[0]\n",
    "    cols = min(max_cols, num_tasks)\n",
    "    rows = math.ceil(num_tasks / cols)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 3 * rows))\n",
    "    axes = np.array(axes).reshape(-1) \n",
    "\n",
    "    for i, t in enumerate(range(num_tasks)):\n",
    "        x = list(range(t, num_tasks - 1))\n",
    "        ax = axes[i]\n",
    "        ax.plot(x, forget_matrix_baseline_mlp[t, t:], marker=\"o\")\n",
    "        ax.plot(x, forget_matrix_seq_cms[t, t:], marker=\"o\")\n",
    "        ax.set_title(f\"Task {t+1}\")\n",
    "        ax.set_xlabel(\"Task\")\n",
    "        ax.set_ylabel(\"Task Forgetting\")\n",
    "        \n",
    "    fig.legend([\"Baseline MLP\", \"Sequential CMS\"], loc=\"lower center\", ncol=2)\n",
    "    fig.suptitle(f\"Task Forgetting evolution per task\", fontsize=14)\n",
    "    fig.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "def plot_cumulative_forgetting(forget_matrix_baseline_mlp, forget_matrix_seq_cms, max_cols=3):\n",
    "    num_tasks = forget_matrix_baseline_mlp.shape[0]\n",
    "    cols = min(max_cols, num_tasks)\n",
    "    rows = math.ceil(num_tasks / cols)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 3 * rows))\n",
    "    axes = np.array(axes).reshape(-1) \n",
    "\n",
    "    for i, t in enumerate(range(num_tasks)):\n",
    "        x = list(range(t, num_tasks - 1))\n",
    "        ax = axes[i]\n",
    "        ax.plot(x, np.cumsum(forget_matrix_baseline_mlp[t, t:]), marker=\"o\")\n",
    "        ax.plot(x, np.cumsum(forget_matrix_seq_cms[t, t:]), marker=\"o\")\n",
    "        ax.set_title(f\"Task {t+1}\")\n",
    "        ax.set_xlabel(\"Task\")\n",
    "        ax.set_ylabel(\"Task Forgetting\")\n",
    "        \n",
    "    fig.legend([\"Baseline MLP\", \"Sequential CMS\"], loc=\"lower center\", ncol=2)\n",
    "    fig.suptitle(f\"Cumulative Forgetting per task\", fontsize=14)\n",
    "    fig.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b37d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_base, A_cms = run_permuted_mnist_cms_experiment(\n",
    "    seed=seed,\n",
    "    verbose=verbose,\n",
    "    T=T,\n",
    "    epochs_per_task=epochs_per_task,\n",
    "    batch_size=batch_size,\n",
    "    base_lr=base_lr,\n",
    "    periods=periods,\n",
    ")\n",
    "F_base = forgetting_matrix(A_base)\n",
    "F_cms = forgetting_matrix(A_cms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f165e292",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_evolution(F_base, F_cms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4c9920",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_task_forgetting(F_base, F_cms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ca68b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cumulative_forgetting(F_base, F_cms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
